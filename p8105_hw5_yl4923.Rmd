---
title: 'p8105_hw5_yl4923'
author: "Yujia Li"
date: "11/19/2021"
output: github_document
---

## Problem 0
# create my public Github repo and local R with a single .Rmd file that renders to github_document
# create a sub-directory to store the local data files used in the assignment, and use relative paths to access these data files
```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(p8105.datasets)

knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1 
```{r}
# 1.1 Create a city_state variable and describe raw data
homi_df = 
  read_csv("./data/homicide-data.csv",na = c("","Unknown")) %>% 
  mutate(
    city_state = str_c(city, state),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )) %>%
  relocate(city_state) %>%
  filter(city_state != "TulsaAL")
```
The homicides data records  `r dim(homi_df)[1]` accidents identified by `r dim(homi_df)[2]` variables in major cities during the past ten years. Key variables include victim characteristics (name, age, sex, etc.), disposition, location (city/state).

The total number of homicides and the number of unsolved homicides within cities are summarized below:
```{r}
homi_stat = 
  homi_df %>% 
  group_by(city_state) %>% 
  summarise(
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")), 
    total_number = n()
    )

knitr::kable(homi_stat)
```

```{r}
# 1.2 prop.test function for Baltimore
baltimore_df = 
  homi_df %>%
  filter(city_state == "BaltimoreMD")

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n())

baltimore_test = 
  prop.test(
    x = baltimore_summary %>% pull(unsolved),
    n = baltimore_summary %>% pull(n)
)

baltimore_test %>% 
  broom::tidy()
```

```{r}
# 1.3 run `prop.test` for each of the cities by writing a function
prop_test_function = function(city_df) {
  city_summary = 
    city_df %>% 
    summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n()
    )
  city_test = 
    prop.test(
      x = city_summary %>% pull(unsolved),
      n = city_summary %>% pull(n))
  
  return(city_test)
}

prop_test_function(baltimore_df) #use Baltimore test the function and then run across all cities

nested_df = 
  homi_df %>%
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>%
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, starts_with("conf"))
```

```{r}
# 1.4 Create a plot that shows the estimates and CIs for each city. Organize cities according to the proportion of unsolved homicides.
nested_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs( title = "The proportion of unsolved homicides and the confidence interval for each city",
        x = "City, State") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2 longtitude study
```{r}
# 2.1 Read in and tidy data with new variables-arm,ID
exp_df = 
  tibble(file_name = list.files("./data/problem2data/", pattern = "*")) %>% 
  mutate(data = map(.x = str_c("./data/problem2data/", file_name, sep = ""), ~ read.csv(.x))) %>%
  separate(file_name, into = c("filename", "postfix"), sep = "\\.") %>% 
  select(-postfix) %>% 
  separate(filename, into = c("arm", "id"), sep = "_", remove = F) %>%
  unnest() %>% 
  gather(key = weeks, value = observation, week_1:week_8) %>% 
  separate(weeks, into = c("prefix", "weeks"), sep = "_") %>% 
  select(-prefix) %>%
  select(id, arm, weeks, observation) %>% 
  mutate(
    arm = factor(arm, levels = c("exp", "con")), 
    id = factor(id), 
    weeks = factor(weeks)
  ) 

head(exp_df)
```

```{r spaghetti plot}
# 2.2 Observations on each subject over time, and comment on differences between groups.
exp_df %>%
  ggplot(aes(x = weeks, y = observation, color = arm)) +
  geom_path(aes(group = id)) +
  geom_point(alpha = .5) + 
  labs(
    title = "Longitudinal study plot",
    x = "Time (week)",
    y = "Observed data"
  )
```
**Comments:** In the beginning of the experiment, the longitudinal data observed both in the control group and the experimental group are quite similar, which is around 1.5. Following along, `exp` arm is generally higher than observations in `con` arm. A t-test with _alternative hypothesis_: true difference in means between group exp and group con is greater than 0 can support the assumption about difference between arms. Since **p.value = `r t.test(observation ~ arm, data = exp_df, alternative = "greater")$p.value`** is smaller than a significant level at 5%, we can conclude that the experimental arm and control arm are significantly different from each other. So the experimental arm may have a positive impact on the longitudinal data.

## Problem 3 iris dataset
```{r}
set.seed(10)

iris_with_missing = 
  iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()
```

```{r function}
# write a function(vector output+ for numeric variables,with the mean of non-missing values; for character variables, with "virginica"))

replace_missing = function(x) {
  
  if (is.numeric(x)) {
    x[is.na(x)] = mean(x, na.rm = TRUE)
  } else if (is.character(x)) {
    x[is.na(x)] = "virginica"
  } else {
    stop("Argument x should be numeric or character")
  }
  x
}

# apply to iris data
iris_complete = map_df(iris_with_missing, replace_missing)
iris_complete
```